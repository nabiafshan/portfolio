[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Afshan’s Portfolio",
    "section": "",
    "text": "To learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "misannotated_lncrnas/Overview.html",
    "href": "misannotated_lncrnas/Overview.html",
    "title": "Afshan's Portfolio",
    "section": "",
    "text": "The aim of this overview is to explain this work as simply as possible.\nFor more biological and technical details, check out the paper in Bioinformatics!\n\n\n\nLong non-coding RNAs (lncRNAs) are defined as non-coding (i.e. don’t code for proteins) RNAs greater than 200 nucleotides in length.\nHowever, recently it was discovered that some open-reading frames within lncRNAs can be translated into small proteins (micropeptides).\nSuch lncRNAs are called misannotated lncRNAs and we want to identify them.\n\n\n\n\n\nExperimental methods:\n\nExpensive!\nTime-consuming!\nCell specific. Need to do a very comprehensive search!\nDifferences across species?\n\nComputational methods:\n\nCoding/Non-Coding classifiers: Normal prediction methods are hamstrung because we don’t know which lncRNAs are misannotated i.e. training datasets have wrong labels.\n\n\nSo there are 2 main problems: * A method able to identify misannotated lncRNAs by sequence alone would be amazing! * It would save time, experimental costs, while being independent of cell-type and species. * If we could generate a list of possible candidate misannotated lncRNAs, experimental validation would be a lot more directed. * Current labels of lncRNAs are wrong. Therefore, a prediction method that doesn’t rely completely on labels would be ideal.\nOur method addresses these problems by relying on training dynamics of deep learning methods to solve the problem of identifying misannotated lncRNAs.\n\n\n\n\nRelying on training dynamics of deep learning models means that:\n\nAt the end of every training epoch, we have the model make coding/non-coding predictions for the sequences in our test set. We save these predictions.\nFinally, we take the mean and standard deviation of coding/non-coding predictions over all epochs.\n\nWhat we’re looking for is sequences with these 2 characteristics:\n\nlabeled non-coding in the dataset (i.e. ground truth is non-coding)\nconsistently classified as coding across epochs.\n\n\nThe following figure demonstrates this idea: * Estimated coding probability across all training epochs shown for five example RNAs for the LSTM model. * We expect coding and non-coding RNAs to have high and low coding probabilities respectively; this is the case for examples A and E. * We are interested in lncRNAs—like B (ENST00000447563)—which have consistently high estimated coding probability, despite having the ground truth-label ‘Non-coding’. * C and D show examples of ambiguous samples, i.e. they show a large change in estimated coding probabilities as model training progresses, so we are not sure whether they are mislabeled or not.\n\nHere’s a training dynamics summary overview plot showing what this looks like for the complete dataset:\n\nEach blue dot is an RNA with ground truth label coding. The orange dots are RNAs with ground truth label non-coding.\ny-axis is the average of ground-truth label predictions across all epochs.\nx-axis is the standard deviation of the ground-truth label predictions across all epochs.\nlncRNAs in the hard-to-learn region of the following figure are considered candidate misannotated lncRNAs.\n\nWhy?– These samples have a low mean and standard deviation for the predicted probability of the ground-truth (i.e. non-coding) class overall training epochs.\nIn other words, RNAs that fall in this region are consistently classified into the non-ground-truth (i.e. coding) class.\n\n\n\n\n\n\nYes it does!\nWe designed a computational experiment where we intentionally mislabel (i.e. flip ground-truth labels of coding to non-coding and vice versa) a part of the dataset.\nAfter flipping the labels, we retrain the model and examine the training dynamics again.\nHere’s what it looks like:\n\nWe sampled 5% of the data with mean (ground truth) >= 0.8 and std (ground truth) <= 0.2.\nThese are samples for which we have medium-high confidence that the ground truth labels are correct (before).\nAfter we flip the labels (coding RNAs become non-coding RNAs and vice-versa), the samples move into the hard-to-classify region of the training dynamics summary plot.\n\n\n\n\n\nWe complied data from 4 experimental sources and found a statistically significant overlap in all cases: 1. cncRNAdb—a manually curated resource of experimentally verified coding ncRNAs 2. Ribo-Seq data-based methods used to find misannotated lncRNAs: 1. FLOSS 2. ORFScore 3. PhyloP\n\n\n\n\n\nThe best way to find a really high-confidence candidate misannotated lncRNA (e.g. for experimental validation) is to aggregate data from many sources!\nTo demonstrate how, we compiled 6 other types of data for a few misannotated lncRNAs we identified: 1. Ribo-Seq identifies RNAs associated with ribosomes, which are likely to be translated. Ribo-Seq P-values (a combined score from FLOSS, ORFScore and PhyloP) show the likelihood of the identified RNA being a true-positive. 2. PeptideShaker analyzes publicly available mass-spectrometry data and provides a confidence score for each peptide. 3. The Top BLAST Hit is the top hit from running the query in BLASTx. 4. The Top hmmer Hit is the hmmer hit with the most significant E-value obtained by running hmmscan on the Pfam profile database that looks for known domains. 5. CNIT, CPC2, CPAT and RNASamba are tools for the coding potential prediction of a given RNA.\n\n\nAlphafold2 provides folding predictions and confidence for given ORFs.\n\n\n\n\n\nFor more nitty-gritty details, checkout the Bioinformatics paper!"
  }
]